{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from os import path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped data/03-21-2020.csv\n",
      "Skipped data/03-20-2020.csv\n",
      "Skipped data/03-19-2020.csv\n",
      "Skipped data/03-18-2020.csv\n",
      "Skipped data/03-17-2020.csv\n",
      "Skipped data/03-16-2020.csv\n",
      "Skipped data/03-15-2020.csv\n",
      "Skipped data/03-14-2020.csv\n",
      "Skipped data/03-13-2020.csv\n",
      "Skipped data/03-12-2020.csv\n",
      "Skipped data/03-11-2020.csv\n",
      "Skipped data/03-10-2020.csv\n",
      "Skipped data/03-09-2020.csv\n",
      "Skipped data/03-08-2020.csv\n",
      "Skipped data/03-07-2020.csv\n",
      "Skipped data/03-06-2020.csv\n",
      "Skipped data/03-05-2020.csv\n",
      "Skipped data/03-04-2020.csv\n",
      "Skipped data/03-03-2020.csv\n",
      "Skipped data/03-02-2020.csv\n",
      "Skipped data/03-01-2020.csv\n",
      "Skipped data/02-29-2020.csv\n",
      "Skipped data/02-28-2020.csv\n",
      "Skipped data/02-27-2020.csv\n",
      "Skipped data/02-26-2020.csv\n",
      "Skipped data/02-25-2020.csv\n",
      "Skipped data/02-24-2020.csv\n",
      "Skipped data/02-23-2020.csv\n",
      "Skipped data/02-22-2020.csv\n",
      "Skipped data/02-21-2020.csv\n",
      "Skipped data/02-20-2020.csv\n",
      "Skipped data/02-19-2020.csv\n",
      "Skipped data/02-18-2020.csv\n",
      "Skipped data/02-17-2020.csv\n",
      "Skipped data/02-16-2020.csv\n",
      "Skipped data/02-15-2020.csv\n",
      "Skipped data/02-14-2020.csv\n",
      "Skipped data/02-13-2020.csv\n",
      "Skipped data/02-12-2020.csv\n",
      "Skipped data/02-11-2020.csv\n",
      "Skipped data/02-10-2020.csv\n",
      "Skipped data/02-09-2020.csv\n",
      "Skipped data/02-08-2020.csv\n",
      "Skipped data/02-07-2020.csv\n",
      "Skipped data/02-06-2020.csv\n",
      "Skipped data/02-05-2020.csv\n",
      "Skipped data/02-04-2020.csv\n",
      "Skipped data/02-03-2020.csv\n",
      "Skipped data/02-02-2020.csv\n",
      "Skipped data/02-01-2020.csv\n",
      "Skipped data/01-31-2020.csv\n",
      "Skipped data/01-30-2020.csv\n",
      "Skipped data/01-29-2020.csv\n",
      "Skipped data/01-28-2020.csv\n",
      "Skipped data/01-27-2020.csv\n",
      "Skipped data/01-26-2020.csv\n",
      "Skipped data/01-25-2020.csv\n",
      "Skipped data/01-24-2020.csv\n",
      "Skipped data/01-23-2020.csv\n",
      "Skipped data/01-22-2020.csv\n"
     ]
    }
   ],
   "source": [
    "date = datetime.today() - timedelta(days = 1)\n",
    "min_date = datetime(year = 2020, month = 1, day = 22)\n",
    "\n",
    "data_dir = \"data\"\n",
    "\n",
    "while date >= min_date:\n",
    "    date_formatted = date.strftime(\"%m-%d-%Y\")\n",
    "    filepath = f\"{data_dir}/{date_formatted}.csv\"\n",
    "    if not path.isfile(filepath):    \n",
    "        url = f\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{date_formatted}.csv\"\n",
    "        dataframe = pd.read_csv(url)\n",
    "        dataframe.to_csv(filepath, index = False)\n",
    "        print(f\"Saved {filepath}\")\n",
    "    else:\n",
    "        print(f\"Skipped {filepath}\")\n",
    "    date = date - timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/02-25-2020.csv', 'data/03-03-2020.csv', 'data/01-27-2020.csv', 'data/03-08-2020.csv', 'data/02-19-2020.csv', 'data/02-03-2020.csv', 'data/02-06-2020.csv', 'data/02-05-2020.csv', 'data/03-07-2020.csv', 'data/03-19-2020.csv', 'data/02-13-2020.csv', 'data/02-20-2020.csv', 'data/02-15-2020.csv', 'data/02-18-2020.csv', 'data/02-01-2020.csv', 'data/02-27-2020.csv', 'data/02-08-2020.csv', 'data/03-02-2020.csv', 'data/02-10-2020.csv', 'data/01-24-2020.csv', 'data/03-04-2020.csv', 'data/01-29-2020.csv', 'data/01-22-2020.csv', 'data/02-02-2020.csv', 'data/01-28-2020.csv', 'data/03-10-2020.csv', 'data/02-07-2020.csv', 'data/02-16-2020.csv', 'data/02-14-2020.csv', 'data/03-17-2020.csv', 'data/02-28-2020.csv', 'data/03-20-2020.csv', 'data/03-11-2020.csv', 'data/03-01-2020.csv', 'data/02-22-2020.csv', 'data/03-18-2020.csv', 'data/02-12-2020.csv', 'data/03-14-2020.csv', 'data/03-13-2020.csv', 'data/03-05-2020.csv', 'data/01-25-2020.csv', 'data/01-31-2020.csv', 'data/03-15-2020.csv', 'data/03-21-2020.csv', 'data/01-26-2020.csv', 'data/02-21-2020.csv', 'data/01-23-2020.csv', 'data/03-09-2020.csv', 'data/02-04-2020.csv', 'data/02-09-2020.csv', 'data/03-12-2020.csv', 'data/03-06-2020.csv', 'data/02-24-2020.csv', 'data/02-29-2020.csv', 'data/01-30-2020.csv', 'data/02-17-2020.csv', 'data/02-11-2020.csv', 'data/03-16-2020.csv', 'data/02-26-2020.csv', 'data/02-23-2020.csv']\n",
      "             Province/State  Country/Region          Last Update  Confirmed  \\\n",
      "0                     Hubei  Mainland China  2020-02-25T15:23:04    64786.0   \n",
      "1                 Guangdong  Mainland China  2020-02-25T08:53:02     1347.0   \n",
      "2                     Henan  Mainland China  2020-02-25T12:43:02     1271.0   \n",
      "3                  Zhejiang  Mainland China  2020-02-25T09:13:05     1205.0   \n",
      "4                     Hunan  Mainland China  2020-02-25T15:03:05     1016.0   \n",
      "...                     ...             ...                  ...        ...   \n",
      "7612  Sacramento County, CA              US  2020-02-21T23:13:16        1.0   \n",
      "7613        San Antonio, TX              US  2020-02-13T18:53:02        1.0   \n",
      "7614            Seattle, WA              US  2020-02-09T07:03:04        1.0   \n",
      "7615              Tempe, AZ              US  2020-02-01T19:43:03        1.0   \n",
      "7616                   None            Iraq  2020-02-23T18:23:06        0.0   \n",
      "\n",
      "      Deaths  Recovered  Latitude  Longitude  \n",
      "0     2563.0    18971.0       NaN        NaN  \n",
      "1        7.0      822.0       NaN        NaN  \n",
      "2       19.0     1002.0       NaN        NaN  \n",
      "3        1.0      808.0       NaN        NaN  \n",
      "4        4.0      768.0       NaN        NaN  \n",
      "...      ...        ...       ...        ...  \n",
      "7612     0.0        0.0       NaN        NaN  \n",
      "7613     0.0        0.0       NaN        NaN  \n",
      "7614     0.0        1.0       NaN        NaN  \n",
      "7615     0.0        0.0       NaN        NaN  \n",
      "7616     0.0        0.0       NaN        NaN  \n",
      "\n",
      "[7617 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "data_files = glob.glob(f\"{data_dir}/*.csv\")\n",
    "\n",
    "daily_dataframes = []\n",
    "\n",
    "print(data_files)\n",
    "\n",
    "for file in data_files:\n",
    "    daily_dataframe = pd.read_csv(file)\n",
    "    daily_dataframes.append(daily_dataframe)\n",
    "\n",
    "combined_data = pd.concat(daily_dataframes, axis=0, ignore_index=True)\n",
    "\n",
    "print(combined_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
